<<<<<<< HEAD
=======
<<<<<<< HEAD
maximize = ifelse(metric == "RMSE", FALSE, TRUE),
trControl = trControl,
tuneLength = tuneLength,
tuneGrid = tuneGrid,
...
)
models[[method]] <- model
}
# result
result <- list(train = train, test = test, models = models)
class(result) <- "quickmodel"
return(result)
}
library(ggplot2)
data(mpg)
data(mtcars)
x <- quickmodel(mpg ~ ., data = mtcars)
quant_models <- c("lm", "rf", "rf", "rpart")
# main function
quickmodel <- function(formula,
data, # all data
metric = "Accuracy",
methods = c(),
trControl = trainControl(),
tuneGrid = NULL,
tuneLength = 3,
partition = 0.8,
...
) {
# if not installed then install
if (!require(caret)) {
install.packages("caret")
}
require("caret")
# extract y varname
y <- all.vars(formula)[1]
# change y var to factor if character
if (is.character(data[[y]])) {
data[[y]] <- factor(data[[y]])
}
# split data into train/test
set.seed(1234)
index <- createDataPartition(data[[y]], p = partition, list = FALSE)
train <- data[index, ]
test <- data[-index, ]
# set evaluation metric
metric <- ifelse(is.factor(data[[y]]), "Accuracy", "RMSE")
# specify which models to train
if (is.factor(data[[y]])) {
methods <- categ_models
} else {
methods <- quant_models
}
# loading required packages
if ("gbm" %in% methods) {
require(gbm)
}
if ("xgbTree" %in% methods) {
require(xgboost)
}
print(methods) # temporary
# model list
models <- list()
# train models
for (method in methods){
model <- train(
formula,
data = train,
method = method,
metric = metric,
maximize = ifelse(metric == "RMSE", FALSE, TRUE),
trControl = trControl,
tuneLength = tuneLength,
tuneGrid = tuneGrid,
...
)
models[[method]] <- model
}
# result
result <- list(train = train, test = test, models = models)
class(result) <- "quickmodel"
return(result)
}
library(ggplot2)
data(mpg)
data(mtcars)
x <- quickmodel(mpg ~ ., data = mtcars)
quant_models <- c("lm", "rf", "rf", "rpart", "gbm")
# main function
quickmodel <- function(formula,
data, # all data
metric = "Accuracy",
methods = c(),
trControl = trainControl(),
tuneGrid = NULL,
tuneLength = 3,
partition = 0.8,
...
) {
# if not installed then install
=======
>>>>>>> e11ae99ca32c0ba177ad5e41b341e8d806402035
if (!require(caret)) {
install.packages("caret")
}
require("caret")
# extract y varname
y <- all.vars(formula)[1]
# change y var to factor if character
if (is.character(data[[y]])) {
data[[y]] <- factor(data[[y]])
}
# split data into train/test
set.seed(1234)
index <- createDataPartition(data[[y]], p = partition, list = FALSE)
train <- data[index, ]
test <- data[-index, ]
# set evaluation metric
metric <- ifelse(is.factor(data[[y]]), "Accuracy", "RMSE")
# specify which models to train
if (is.factor(data[[y]])) {
methods <- categ_models
} else {
methods <- quant_models
}
# loading required packages
if ("gbm" %in% methods) {
require(gbm)
}
if ("xgbTree" %in% methods) {
require(xgboost)
}
print(methods) # temporary
# model list
models <- list()
# train models
for (method in methods){
model <- train(
formula,
data = train,
method = method,
metric = metric,
maximize = ifelse(metric == "RMSE", FALSE, TRUE),
trControl = trControl,
tuneLength = tuneLength,
tuneGrid = tuneGrid,
...
)
models[[method]] <- model
}
# result
result <- list(train = train, test = test, models = models)
class(result) <- "quickmodel"
return(result)
}
library(ggplot2)
data(mpg)
data(mtcars)
x <- quickmodel(mpg ~ ., data = mtcars)
quant_models <- c("lm", "rf", "rf", "rpart", "glmnet")
# main function
quickmodel <- function(formula,
data, # all data
metric = "Accuracy",
methods = c(),
trControl = trainControl(),
tuneGrid = NULL,
tuneLength = 3,
partition = 0.8,
...
) {
>>>>>>> 1a9ddefed624102e09f15e1e138021c158acb86a
# if not installed then install
if (!require(caret)) {
install.packages("caret")
}
require("caret")
# extract y varname
y <- all.vars(formula)[1]
# change y var to factor if character
if (is.character(data[[y]])) {
data[[y]] <- factor(data[[y]])
}
# split data into train/test
set.seed(seed)
index <- createDataPartition(data[[y]], p = partition, list = FALSE)
train <- data[index, ]
test <- data[-index, ]
# set evaluation metric if not specified
if (missing(metric)) {
metric <- ifelse(is.factor(data[[y]]), "Accuracy", "RMSE")
}
# specify which models to train
if (missing(methods)){
if (is.factor(data[[y]])) {
methods <- categ_models
} else {
methods <- quant_models
}
}
# loading required packages
if ("gbm" %in% methods) {
require(gbm)
}
# model list
models <- list()
# train models
for (method in methods){
set.seed(seed)
model <- train(
formula,
data = train,
method = method,
metric = metric,
trControl = trControl,
tuneLength = tuneLength,
tuneGrid = tuneGrid,
...
)
models[[method]] <- model
}
# result
result <- list(train = train, test = test, models = models)
class(result) <- "quickmodel"
return(result)
}
<<<<<<< HEAD
x=quickmodel(Age~., data = PIMA)
=======
x <- quickmodel(mpg ~ ., data = mtcars)
metric = NULL
!is.null(metric)
is.null(metric)
<<<<<<< HEAD
library(usethis)
data(PIMA, package="regclass")
use_data(PIMA)
data(Boston, package="MASS")
View(Boston)
use_package("caret")
use_package("randomForest")
use_package("rpart")
use_package("gbm")
use_package("plyr")
use_package("glmnet")
use_package("Matrix")
library(foreach)
install.packages("doParallel")
use_data(Boston)
#manufacturing info
#colt
colt_revolvers=read_csv("/Users/liusimin/Desktop/Gun Safety/Carceral/colt/colt_revolvers3.csv")
library(readr)
library(dplyr)
#colt
colt_revolvers=read_csv("/Users/liusimin/Desktop/Gun Safety/Carceral/colt/colt_revolvers3.csv")
colt_sap=read_csv("/Users/liusimin/Desktop/Gun Safety/Carceral/colt/colt_sap3.csv")
colt_rifle=read_csv("/Users/liusimin/Desktop/Gun Safety/Carceral/colt/colt_rifles3.csv")
colt_shotgun=read_csv("/Users/liusimin/Desktop/Gun Safety/Carceral/colt/coltguns.csv")
#heckler koch
heckler=read_csv("/Users/liusimin/Desktop/Gun Safety/Carceral/heckler koch/heckler koch guns3.csv")
#henry
henry=read_csv("/Users/liusimin/Desktop/Gun Safety/Carceral/henry/henry guns3.csv")
#fn herstal
fnherstal=read_csv("/Users/liusimin/Desktop/Gun Safety/Carceral/herstal/FN herstal guns3.csv")
#high standard
highstandard=read_csv("/Users/liusimin/Desktop/Gun Safety/Carceral/high standard/high standard guns3.csv")
#mossberg
mossberg=read_csv("/Users/liusimin/Desktop/Gun Safety/Carceral/mossberg/mossberg guns3.csv")
#whichester
whinchester=read_csv("/Users/liusimin/Desktop/Gun Safety/Carceral/winchester/winchester guns3.csv")
#sharps
sharps=read_csv("/Users/liusimin/Desktop/Gun Safety/Carceral/sharps/sharps guns.csv")
#remington
remington=read_csv("/Users/liusimin/Desktop/Gun Safety/Carceral/remington/remington guns3.csv")
#ruger
ruger=read_csv("/Users/liusimin/Desktop/Gun Safety/Carceral/ruger/ruger guns4.csv")
#barrett
barrett=read_csv("/Users/liusimin/Desktop/Gun Safety/Carceral/barrett/barrett guns3.csv")
#append
allguns=list(colt_revolvers=colt_revolvers, colt_sap=colt_sap, colt_rifle=colt_rifle,
colt_shotgun=colt_shotgun, heckler=heckler, henry=henry,
fnherstal=fnherstal, highstandard=highstandard, mossberg=mossberg,
whinchester=whinchester, sharps=sharps, remington=remington,
ruger=ruger, barrett=barrett)
manus=bind_rows(allguns, .id = "source")
colnames(manus)[colnames(manus)=="...1"]="model"
#merge cols--------
# "In service"="In Service"="Production"="Produced"
# "length"="Length"="Overall length"="Overall Length"
# "Barrel length"="Barrel Length"
manus$`0`=NULL
manus$Spouse=NULL
manus$Children=NULL
manus$`Occupation(s)`=NULL
manus$Born=NULL
manus$Died=NULL
manus$`Alma mater`=NULL
# Use coalesce to create Column3
manus$in_service_time = coalesce(manus$`In service`, manus$`In Service`,
manus$Production, manus$Produced, as.character(submanus$year))
manus$in_service_time = coalesce(manus$`In service`, manus$`In Service`,
manus$Production, manus$Produced, as.character(manus$year))
manus$length = coalesce(manus$length, manus$Length,
manus$`Overall length`, manus$`Overall Length`)
manus$barrel_length = coalesce(manus$`Barrel length`, manus$`Barrel Length`)
manus$action_type = coalesce(manus$`Action Type`, manus$Action)
delete=c("In service", "In Service", "Production", "Produced", "Length", "Overall length", "Overall Length",
"Barrel length", "Barrel Length", "Action Type", "Action")
manus2=manus %>% select(-delete)
submanus=manus2 %>% select(in_service_time,source, model, Type, Manufacturer,name, category, action_type)
gsub("\\['(.*?)'\\]", "\\1", x)
# clean columns----------
# Function to remove square brackets and single quotes
remove_brackets <- function(x) {
gsub("\\['(.*?)'\\]", "\\1", x)
}
# Apply the function to all columns
manus2 <- apply(manus2, 2, remove_brackets)
# Convert the result back to a data frame
manus2 <- as.data.frame(manus2)
remove_comma = function(x){
strsplit(x, ',')
}
manus2=apply(manus2, 2, remove_comma)
manus2=as_tibble(manus2)
View(manus2)
manus2=manus %>% select(-delete)
submanus=manus2 %>% select(in_service_time,source, model, Type, Manufacturer,name, category, action_type)
# clean columns----------
# Function to remove square brackets and single quotes
remove_brackets <- function(x) {
gsub("\\['(.*?)'\\]", "\\1", x)
}
# Apply the function to all columns
manus2 <- apply(manus2, 2, remove_brackets)
# Convert the result back to a data frame
manus2 <- as.data.frame(manus2)
?gsub
gsub("','", ",", x)
remove_quotes <- function(x) {
gsub("','", ",", x)
}
# Apply the function to all columns
manus2 <- apply(manus2, 2, remove_quotes)
# Convert the result back to a data frame
manus2 <- as.data.frame(manus2)
x = remove_quotes(manus$barrel_length[2]
)
x
remove_quotes <- function(x) {
gsub("', '", ",", x)
}
x = remove_quotes(manus$barrel_length[2]
)
# Apply the function to all columns
manus2 <- apply(manus2, 2, remove_quotes)
# Convert the result back to a data frame
manus2 <- as.data.frame(manus2)
View(manus2)
submanus=manus2 %>% select(in_service_time,source, model, Type, Manufacturer,name, category, action_type)
library(qacBase)
contents(submanus)
#manufacturing info
library(readr)
library(dplyr)
#colt
colt_revolvers=read_csv("/Users/liusimin/Desktop/Gun Safety/Carceral/colt/colt_revolvers3.csv")
colt_sap=read_csv("/Users/liusimin/Desktop/Gun Safety/Carceral/colt/colt_sap3.csv")
colt_rifle=read_csv("/Users/liusimin/Desktop/Gun Safety/Carceral/colt/colt_rifles3.csv")
colt_shotgun=read_csv("/Users/liusimin/Desktop/Gun Safety/Carceral/colt/coltguns.csv")
#heckler koch
heckler=read_csv("/Users/liusimin/Desktop/Gun Safety/Carceral/heckler koch/heckler koch guns3.csv")
#henry
henry=read_csv("/Users/liusimin/Desktop/Gun Safety/Carceral/henry/henry guns3.csv")
#fn herstal
fnherstal=read_csv("/Users/liusimin/Desktop/Gun Safety/Carceral/herstal/FN herstal guns3.csv")
#high standard
highstandard=read_csv("/Users/liusimin/Desktop/Gun Safety/Carceral/high standard/high standard guns3.csv")
#mossberg
mossberg=read_csv("/Users/liusimin/Desktop/Gun Safety/Carceral/mossberg/mossberg guns3.csv")
#winchester
winchester=read_csv("/Users/liusimin/Desktop/Gun Safety/Carceral/winchester/winchester guns3.csv")
#sharps
sharps=read_csv("/Users/liusimin/Desktop/Gun Safety/Carceral/sharps/sharps guns.csv")
#remington
remington=read_csv("/Users/liusimin/Desktop/Gun Safety/Carceral/remington/remington guns3.csv")
#ruger
ruger=read_csv("/Users/liusimin/Desktop/Gun Safety/Carceral/ruger/ruger guns4.csv")
#barrett
barrett=read_csv("/Users/liusimin/Desktop/Gun Safety/Carceral/barrett/barrett guns3.csv")
#append
allguns=list(colt_revolvers=colt_revolvers, colt_sap=colt_sap, colt_rifle=colt_rifle,
colt_shotgun=colt_shotgun, heckler=heckler, henry=henry,
fnherstal=fnherstal, highstandard=highstandard, mossberg=mossberg,
winchester=winchester, sharps=sharps, remington=remington,
ruger=ruger, barrett=barrett)
manus=bind_rows(allguns, .id = "source")
colnames(manus)[colnames(manus)=="...1"]="model"
#merge cols--------
# "In service"="In Service"="Production"="Produced"
# "length"="Length"="Overall length"="Overall Length"
# "Barrel length"="Barrel Length"
manus$`0`=NULL
manus$Spouse=NULL
manus$Children=NULL
manus$`Occupation(s)`=NULL
manus$Born=NULL
manus$Died=NULL
manus$`Alma mater`=NULL
# Use coalesce to create Column3
manus$in_service_time = coalesce(manus$`In service`, manus$`In Service`,
manus$Production, manus$Produced, as.character(manus$year))
manus$length = coalesce(manus$length, manus$Length,
manus$`Overall length`, manus$`Overall Length`)
manus$barrel_length = coalesce(manus$`Barrel length`, manus$`Barrel Length`)
manus$action_type = coalesce(manus$`Action Type`, manus$Action)
delete=c("In service", "In Service", "Production", "Produced", "Length", "Overall length", "Overall Length",
"Barrel length", "Barrel Length", "Action Type", "Action")
manus2=manus %>% select(-delete)
submanus=manus2 %>% select(in_service_time,source, model, Type, Manufacturer,name, category, action_type)
# clean columns----------
# Function to remove square brackets and single quotes
remove_brackets <- function(x) {
gsub("\\['(.*?)'\\]", "\\1", x)
}
remove_quotes <- function(x) {
gsub("', '", ",", x)
}
x = remove_quotes(manus$barrel_length[2]
)
# Apply the function to all columns
manus2 <- apply(manus2, 2, remove_quotes)
# Convert the result back to a data frame
manus2 <- as.data.frame(manus2)
View(manus2)
View(submanus)
contents(submanus)
acgs=read_csv("/Users/liusimin/Desktop/Gun Safety/after10-20/ACG_patents.csv")
View(acgs)
acgs$inventorCountry
acgs$inventorCountry[19145]
View(submanus)
#-----------
# most prolific inventors/locations
# inventors
# f41 a 17= descriptives /visualization / when does this category first appear (1st instance)/ chronologically
write_csv(submanus, "/Users/liusimin/Desktop/Gun Safety/after10-20/manufactureres_subset.csv")
write_csv(submanus, "/Users/liusimin/Desktop/Gun Safety/after10-20/manufactureres_all.csv")
write_csv(manus, "/Users/liusimin/Desktop/Gun Safety/after10-20/manufactureres_all.csv")
=======
data("mtcars")
# Testing -----------------------------------------------------------------
data("PIMA", package="regclass")
install.packages("regclass")
>>>>>>> 1a9ddefed624102e09f15e1e138021c158acb86a
# main function
quickmodel <- function(formula,
data, # all data
metric ,
methods ,
trControl = trainControl(),
tuneGrid = NULL,
tuneLength = 3,
partition = 0.8,
seed=1234,
...
) {
#stop when the input dataset is too small
if (nrow(data)<100){
stop("Dataset too small.")
}
# quantitative
quant_models <- c("lm", "knn", "rf",
"rpart",
# "gbm",
"glmnet")
# categorical
categ_models <- c("glm", "knn", "rf", "rpart", "gbm", "glmnet")
# if not installed then install
if (!require(caret)) {
install.packages("caret")
}
require("caret")
# extract y varname
y <- all.vars(formula)[1]
# change y var to factor if character
if (is.character(data[[y]])) {
data[[y]] <- factor(data[[y]])
}
# split data into train/test
set.seed(seed)
index <- createDataPartition(data[[y]], p = partition, list = FALSE)
train <- data[index, ]
test <- data[-index, ]
# set evaluation metric if not specified
if (missing(metric)) {
metric <- ifelse(is.factor(data[[y]]), "Accuracy", "RMSE")
}
# specify which models to train
if (missing(methods)){
if (is.factor(data[[y]])) {
methods <- categ_models
} else {
methods <- quant_models
}
}
# loading required packages
if ("gbm" %in% methods) {
require(gbm)
}
# model list
models <- list()
# train models
for (method in methods){
set.seed(seed)
model <- train(
formula,
data = train,
method = method,
metric = metric,
trControl = trControl,
tuneLength = tuneLength,
tuneGrid = tuneGrid,
...
)
models[[method]] <- model
}
# result
result <- list(train = train, test = test, models = models)
class(result) <- "quickmodel"
return(result)
}
x=quickmodel(Age~., data = PIMA)
# main function
quickmodel <- function(formula,
data, # all data
metric ,
methods ,
trControl = trainControl(),
tuneGrid = NULL,
tuneLength = 3,
partition = 0.8,
seed=1234,
...
) {
#stop when the input dataset is too small
if (nrow(data)<100){
stop("Dataset too small.")
}
# quantitative
quant_models <- c("lm", "knn", "rf",
"rpart",
"gbm",
"glmnet")
# categorical
categ_models <- c("glm", "knn", "rf", "rpart", "gbm", "glmnet")
# if not installed then install
if (!require(caret)) {
install.packages("caret")
}
require("caret")
# extract y varname
y <- all.vars(formula)[1]
# change y var to factor if character
if (is.character(data[[y]])) {
data[[y]] <- factor(data[[y]])
}
# split data into train/test
set.seed(seed)
index <- createDataPartition(data[[y]], p = partition, list = FALSE)
train <- data[index, ]
test <- data[-index, ]
# set evaluation metric if not specified
if (missing(metric)) {
metric <- ifelse(is.factor(data[[y]]), "Accuracy", "RMSE")
}
# specify which models to train
if (missing(methods)){
if (is.factor(data[[y]])) {
methods <- categ_models
} else {
methods <- quant_models
}
}
# loading required packages
if ("gbm" %in% methods) {
require(gbm)
}
# model list
models <- list()
# train models
for (method in methods){
set.seed(seed)
model <- train(
formula,
data = train,
method = method,
metric = metric,
trControl = trControl,
tuneLength = tuneLength,
tuneGrid = tuneGrid,
...
)
models[[method]] <- model
}
# result
result <- list(train = train, test = test, models = models)
class(result) <- "quickmodel"
return(result)
}
x=quickmodel(Age~., data = PIMA)
View(x)
x[["models"]][["lm"]][["results"]]
#' @title Build multiple models
#' @description \code{quickmodel} will build multiple machine learning models with one function call.
#' @param formula An object of class "formula" (or one that can be coerced to that class): a symbolic description of the model to be fitted.
#' @param data Data frame from which variables specified in formula are preferentially to be taken.
#' @param metric A string that specifies what summary metric will be used to select the optimal model. By default, possible values are "RMSE" and "Rsquared" for regression and "Accuracy" for classification.
#' @param methods A character vector specifying which classification or regression model to use. By default, possible values are \code{c("lm", "knn", "rf", "rpart", "gbm", "glmnet")} for regression and \code{c("glm", "knn", "rf", "rpart", "gbm", "glmnet")} for classification.
#' @param trControl A list of values that define how this function acts. Default: trainControl()
#' @param tuneGrid A data frame with possible tuning values. The columns are named the same as the tuning parameters in each method preceded by a period (e.g. .decay, .lambda)., Default: NULL
#' @param tuneLength an integer denoting the number of levels for each tuning parameter that should be generated by createGrid. (NOTE: If given, this argument must be named.), Default: 3
#' @param partition The partition rate. Default: 0.8
#' @param seed The seed to do a random partition. Default: 1234
#' @param ... Optional parameters for \code{train} in \code{caret}
#' @return A list of class \code{quickmodel} with 4 components:
#' \describe{
#' \item{train}{The train dataset}
#' \item{test}{The test dataset}
#' \item{models}{A list of models}
#' \item{methods}{A character vector of machine learning models}
#' }
#' @details
#’ This function will take data and partition it into train and test datasets by the partition rate. It trains multiple machine learning models specified in methods.
#’ Note: If the user chooses to use any method that are not mentioned in default methods, they have to install and load corresponding packages first.
#' @examples
#’ data("PIMA", package="regclass")
#’ # classification models
#’ x=quickmodel(Diabetes~., data = PIMA)
#’ # regression models
#’ x=quickmodel(Age~., data = PIMA)
#' @import caret
#' @import randomForest
#' @import rpart
#' @import gbm
#' @import plyr
#' @import glmnet
#' @import Matrix
#' @rdname quickmodel
#' @export
quickmodel <- function(formula,
data, # all data
metric ,
methods ,
trControl = trainControl(),
tuneGrid = NULL,
tuneLength = 3,
partition = 0.8,
seed = 1234,
...
) {
# stop when the input dataset is too small
if (nrow(data)<100){
stop("Dataset too small.")
}
# quantitative
quant_models <- c("lm", "knn", "rf",
"rpart",
"gbm",
"glmnet")
# categorical
categ_models <- c("glm", "knn", "rf", "rpart", "gbm", "glmnet")
# if not installed then install
if (!require(caret)) {
install.packages("caret")
}
require("caret")
# extract y varname
y <- all.vars(formula)[1]
# change y var to factor if character
if (is.character(data[[y]])) {
data[[y]] <- factor(data[[y]])
}
# split data into train/test
set.seed(seed)
index <- createDataPartition(data[[y]], p = partition, list = FALSE)
train <- data[index, ]
test <- data[-index, ]
# set evaluation metric if not specified
if (missing(metric)) {
metric <- ifelse(is.factor(data[[y]]), "Accuracy", "RMSE")
}
# specify which models to train
if (missing(methods)){
if (is.factor(data[[y]])) {
methods <- categ_models
} else {
methods <- quant_models
}
}
# loading required packages
if ("gbm" %in% methods) {
require(gbm)
}
# model list
models <- list()
# train models
for (method in methods){
set.seed(seed)
model <- train(
formula,
data = train,
method = method,
metric = metric,
trControl = trControl,
tuneLength = tuneLength,
tuneGrid = tuneGrid,
...
)
models[[method]] <- model
}
# result
result <- list(train = train,
test = test,
methods = methods,
models = models)
class(result) <- "quickmodel"
return(result)
}
library(ggplot2)
data(mpg)
View(mpg)
x <- quickmodel(cty ~ ., mpg)
View(x)
# main function
bestmodels <- function(models_list) {
best <- list()
# Finding the best model for quantitative models (lowest RMSE)
quant_models <- c("lm", "knn", "rf", "rpart", "gbm", "glmnet")
quant_models_list <- Filter(function(model) model$method %in% quant_models, models_list$models)
if (length(quant_models_list) > 0) {
# Extract RMSE values for each model in quant_models_list
rmse_values <- unlist(lapply(quant_models_list, function(model) model$results$RMSE))
if (length(rmse_values) > 0) {
# Find the index of the minimum RMSE value
best_model_index <- which.min(rmse_values)
# Check which model has the lowest RMSE value
print(paste("Best RMSE:", rmse_values[best_model_index]))
print(quant_models_list)
# Retrieve the best model based on the index
best_quant_model <- quant_models_list[[best_model_index]]
print(best_quant_model)
} else {
print("No RMSE values found.")
}
} else {
print("No models found for quantitative criteria.")
}
# Finding the best model for categorical models (highest Accuracy)
categ_models <- c("glm", "knn", "rf", "rpart", "gbm", "glmnet")
categ_models_list <- Filter(function(model) model$method %in% categ_models, models_list$models)
if (length(categ_models_list) > 0) {
# Extract Accuracy values for each model in categ_models_list
accuracy_values <- unlist(lapply(categ_models_list, function(model) model$results$Accuracy))
if (length(accuracy_values) > 0) {
# Find the index of the maximum Accuracy value
best_model_index <- which.max(accuracy_values)
# Retrieve the best model based on the index
best_categ_model <- categ_models_list[[best_model_index]]
best[["categorical"]] <- best_categ_model
} else {
best[["categorical"]] <- NULL
}
} else {
best[["categorical"]] <- NULL
}
return(best)
}
bestmodels(x)
data("PIMA")
data("PIMA", package = "regclass")
models_list <- quickmodel(Diabetes ~ ., PIMA)
#' @title Build multiple models
#' @description \code{quickmodel} will build multiple machine learning models with one function call.
#' @param formula An object of class "formula" (or one that can be coerced to that class): a symbolic description of the model to be fitted.
#' @param data Data frame from which variables specified in formula are preferentially to be taken.
#' @param metric A string that specifies what summary metric will be used to select the optimal model. By default, possible values are "RMSE" and "Rsquared" for regression and "Accuracy" for classification.
#' @param methods A character vector specifying which classification or regression model to use. By default, possible values are \code{c("lm", "knn", "rf", "rpart", "gbm", "glmnet")} for regression and \code{c("glm", "knn", "rf", "rpart", "gbm", "glmnet")} for classification.
#' @param trControl A list of values that define how this function acts. Default: trainControl()
#' @param tuneGrid A data frame with possible tuning values. The columns are named the same as the tuning parameters in each method preceded by a period (e.g. .decay, .lambda)., Default: NULL
#' @param tuneLength an integer denoting the number of levels for each tuning parameter that should be generated by createGrid. (NOTE: If given, this argument must be named.), Default: 3
#' @param partition The partition rate. Default: 0.8
#' @param seed The seed to do a random partition. Default: 1234
#' @param ... Optional parameters for \code{train} in \code{caret}
#' @return A list of class \code{quickmodel} with 4 components:
#' \describe{
#' \item{train}{The train dataset}
#' \item{test}{The test dataset}
#' \item{models}{A list of models}
#' \item{methods}{A character vector of machine learning models}
#' }
#' @details
#’ This function will take data and partition it into train and test datasets by the partition rate. It trains multiple machine learning models specified in methods.
#’ Note: If the user chooses to use any method that are not mentioned in default methods, they have to install and load corresponding packages first.
#' @examples
#’ data("PIMA", package="regclass")
#’ # classification models
#’ x=quickmodel(Diabetes~., data = PIMA)
#’ # regression models
#’ x=quickmodel(Age~., data = PIMA)
#' @import caret
#' @import randomForest
#' @import rpart
#' @import gbm
#' @import plyr
#' @import glmnet
#' @import Matrix
#' @rdname quickmodel
#' @export
quickmodel <- function(formula,
data, # all data
metric ,
methods ,
trControl = trainControl(),
tuneGrid = NULL,
tuneLength = 3,
partition = 0.8,
seed = 1234,
...
) {
# stop when the input dataset is too small
if (nrow(data)<100){
stop("Dataset too small.")
}
# quantitative
quant_models <- c("lm", "knn", "rf",
"rpart",
"gbm",
"glmnet")
# categorical
categ_models <- c("glm", "knn", "rf", "rpart", "gbm", "glmnet")
# if not installed then install
if (!require(caret)) {
install.packages("caret")
}
require("caret")
# extract y varname
y <- all.vars(formula)[1]
# change y var to factor if character
if (is.character(data[[y]])) {
data[[y]] <- factor(data[[y]])
}
# split data into train/test
set.seed(seed)
index <- createDataPartition(data[[y]], p = partition, list = FALSE)
train <- data[index, ]
test <- data[-index, ]
# set evaluation metric if not specified
if (missing(metric)) {
metric <- ifelse(is.factor(data[[y]]), "Accuracy", "RMSE")
}
# specify which models to train
if (missing(methods)){
if (is.factor(data[[y]])) {
methods <- categ_models
} else {
methods <- quant_models
}
}
# loading required packages
if ("gbm" %in% methods) {
require(gbm)
}
# model list
models <- list()
# train models
for (method in methods){
set.seed(seed)
model <- train(
formula,
data = train,
method = method,
metric = metric,
trControl = trControl,
tuneLength = tuneLength,
tuneGrid = tuneGrid,
...
)
models[[method]] <- model
}
# result
result <- list(train = train,
test = test,
methods = methods,
models = models)
class(result) <- "quickmodel"
return(result)
}
<<<<<<< HEAD
models_list <- quickmodel(Diabetes ~ ., PIMA)
best <- list()
# Finding the best model for quantitative models (lowest RMSE)
quant_models <- c("lm", "knn", "rf", "rpart", "gbm", "glmnet")
quant_models_list <- Filter(function(model) model$method %in% quant_models, models_list$models)
View(quant_models_list)
# Extract RMSE values for each model in quant_models_list
rmse_values <- unlist(lapply(quant_models_list, function(model) model$results$RMSE))
best <- list()
# Finding the best model for quantitative models (lowest RMSE)
quant_models <- c("lm", "knn", "rf", "rpart", "gbm", "glmnet")
quant_models_list <- Filter(function(model) model$method %in% quant_models, models_list$models)
# Extract RMSE values for each model in quant_models_list
rmse_values <- unlist(lapply(quant_models_list, function(model) model$results$RMSE))
=======
x=quickmodel(Age~., data = PIMA)
View(x)
x[["models"]][["lm"]][["results"]]
>>>>>>> e11ae99ca32c0ba177ad5e41b341e8d806402035
>>>>>>> 1a9ddefed624102e09f15e1e138021c158acb86a
