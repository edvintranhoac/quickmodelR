# if not installed then install
if (!require(caret)) {
install.packages("caret")
}
require("caret")
# extract y varname
y <- all.vars(formula)[1]
# change y var to factor if character
if (is.character(data[[y]])) {
data[[y]] <- factor(data[[y]])
}
# split data into train/test
set.seed(seed)
index <- createDataPartition(data[[y]], p = partition, list = FALSE)
train <- data[index, ]
test <- data[-index, ]
# set evaluation metric if not specified
if (missing(metric)) {
metric <- ifelse(is.factor(data[[y]]), "Accuracy", "RMSE")
}
# specify which models to train
if (missing(methods)){
if (is.factor(data[[y]])) {
methods <- categ_models
} else {
methods <- quant_models
}
}
# loading required packages
if ("gbm" %in% methods) {
require(gbm)
}
# model list
models <- list()
# train models
for (method in methods){
set.seed(seed)
model <- train(
formula,
data = train,
method = method,
metric = metric,
trControl = trControl,
tuneLength = tuneLength,
tuneGrid = tuneGrid,
...
)
models[[method]] <- model
}
# result
result <- list(train = train, test = test, models = models)
class(result) <- "quickmodel"
return(result)
}
x=quickmodel(Age~., data = PIMA)
# main function
quickmodel <- function(formula,
data, # all data
metric ,
methods ,
trControl = trainControl(),
tuneGrid = NULL,
tuneLength = 3,
partition = 0.8,
seed=1234,
...
) {
#stop when the input dataset is too small
if (nrow(data)<100){
stop("Dataset too small.")
}
# quantitative
quant_models <- c("lm", "knn", "rf",
"rpart",
# "gbm",
"glmnet")
# categorical
categ_models <- c("glm", "knn", "rf", "rpart", "gbm", "glmnet")
# if not installed then install
if (!require(caret)) {
install.packages("caret")
}
require("caret")
# extract y varname
y <- all.vars(formula)[1]
# change y var to factor if character
if (is.character(data[[y]])) {
data[[y]] <- factor(data[[y]])
}
# split data into train/test
set.seed(seed)
index <- createDataPartition(data[[y]], p = partition, list = FALSE)
train <- data[index, ]
test <- data[-index, ]
# set evaluation metric if not specified
if (missing(metric)) {
metric <- ifelse(is.factor(data[[y]]), "Accuracy", "RMSE")
}
# specify which models to train
if (missing(methods)){
if (is.factor(data[[y]])) {
methods <- categ_models
} else {
methods <- quant_models
}
}
# loading required packages
if ("gbm" %in% methods) {
require(gbm)
}
# model list
models <- list()
# train models
for (method in methods){
set.seed(seed)
model <- train(
formula,
data = train,
method = method,
metric = metric,
trControl = trControl,
tuneLength = tuneLength,
tuneGrid = tuneGrid,
...
)
models[[method]] <- model
}
# result
result <- list(train = train, test = test, models = models)
class(result) <- "quickmodel"
return(result)
}
x=quickmodel(Age~., data = PIMA)
# main function
quickmodel <- function(formula,
data, # all data
metric ,
methods ,
trControl = trainControl(),
tuneGrid = NULL,
tuneLength = 3,
partition = 0.8,
seed=1234,
...
) {
#stop when the input dataset is too small
if (nrow(data)<100){
stop("Dataset too small.")
}
# quantitative
quant_models <- c("lm", "knn", "rf",
"rpart",
"gbm",
"glmnet")
# categorical
categ_models <- c("glm", "knn", "rf", "rpart", "gbm", "glmnet")
# if not installed then install
if (!require(caret)) {
install.packages("caret")
}
require("caret")
# extract y varname
y <- all.vars(formula)[1]
# change y var to factor if character
if (is.character(data[[y]])) {
data[[y]] <- factor(data[[y]])
}
# split data into train/test
set.seed(seed)
index <- createDataPartition(data[[y]], p = partition, list = FALSE)
train <- data[index, ]
test <- data[-index, ]
# set evaluation metric if not specified
if (missing(metric)) {
metric <- ifelse(is.factor(data[[y]]), "Accuracy", "RMSE")
}
# specify which models to train
if (missing(methods)){
if (is.factor(data[[y]])) {
methods <- categ_models
} else {
methods <- quant_models
}
}
# loading required packages
if ("gbm" %in% methods) {
require(gbm)
}
# model list
models <- list()
# train models
for (method in methods){
set.seed(seed)
model <- train(
formula,
data = train,
method = method,
metric = metric,
trControl = trControl,
tuneLength = tuneLength,
tuneGrid = tuneGrid,
...
)
models[[method]] <- model
}
# result
result <- list(train = train, test = test, models = models)
class(result) <- "quickmodel"
return(result)
}
x=quickmodel(Age~., data = PIMA)
View(x)
x[["models"]][["lm"]][["results"]]
#' @title Build multiple models
#' @description \code{quickmodel} will build multiple machine learning models with one function call.
#' @param formula An object of class "formula" (or one that can be coerced to that class): a symbolic description of the model to be fitted.
#' @param data Data frame from which variables specified in formula are preferentially to be taken.
#' @param metric A string that specifies what summary metric will be used to select the optimal model. By default, possible values are "RMSE" and "Rsquared" for regression and "Accuracy" for classification.
#' @param methods A character vector specifying which classification or regression model to use. By default, possible values are \code{c("lm", "knn", "rf", "rpart", "gbm", "glmnet")} for regression and \code{c("glm", "knn", "rf", "rpart", "gbm", "glmnet")} for classification.
#' @param trControl A list of values that define how this function acts. Default: trainControl()
#' @param tuneGrid A data frame with possible tuning values. The columns are named the same as the tuning parameters in each method preceded by a period (e.g. .decay, .lambda)., Default: NULL
#' @param tuneLength an integer denoting the number of levels for each tuning parameter that should be generated by createGrid. (NOTE: If given, this argument must be named.), Default: 3
#' @param partition The partition rate. Default: 0.8
#' @param seed The seed to do a random partition. Default: 1234
#' @param ... Optional parameters for \code{train} in \code{caret}
#' @return A list of class \code{quickmodel} with 4 components:
#' \describe{
#' \item{train}{The train dataset}
#' \item{test}{The test dataset}
#' \item{models}{A list of models}
#' \item{methods}{A character vector of machine learning models}
#' }
#' @details
#’ This function will take data and partition it into train and test datasets by the partition rate. It trains multiple machine learning models specified in methods.
#’ Note: If the user chooses to use any method that are not mentioned in default methods, they have to install and load corresponding packages first.
#' @examples
#’ data("PIMA", package="regclass")
#’ # classification models
#’ x=quickmodel(Diabetes~., data = PIMA)
#’ # regression models
#’ x=quickmodel(Age~., data = PIMA)
#' @import caret
#' @import randomForest
#' @import rpart
#' @import gbm
#' @import plyr
#' @import glmnet
#' @import Matrix
#' @rdname quickmodel
#' @export
quickmodel <- function(formula,
data, # all data
metric ,
methods ,
trControl = trainControl(),
tuneGrid = NULL,
tuneLength = 3,
partition = 0.8,
seed = 1234,
...
) {
# stop when the input dataset is too small
if (nrow(data)<100){
stop("Dataset too small.")
}
# quantitative
quant_models <- c("lm", "knn", "rf",
"rpart",
"gbm",
"glmnet")
# categorical
categ_models <- c("glm", "knn", "rf", "rpart", "gbm", "glmnet")
# if not installed then install
if (!require(caret)) {
install.packages("caret")
}
require("caret")
# extract y varname
y <- all.vars(formula)[1]
# change y var to factor if character
if (is.character(data[[y]])) {
data[[y]] <- factor(data[[y]])
}
# split data into train/test
set.seed(seed)
index <- createDataPartition(data[[y]], p = partition, list = FALSE)
train <- data[index, ]
test <- data[-index, ]
# set evaluation metric if not specified
if (missing(metric)) {
metric <- ifelse(is.factor(data[[y]]), "Accuracy", "RMSE")
}
# specify which models to train
if (missing(methods)){
if (is.factor(data[[y]])) {
methods <- categ_models
} else {
methods <- quant_models
}
}
# loading required packages
if ("gbm" %in% methods) {
require(gbm)
}
# model list
models <- list()
# train models
for (method in methods){
set.seed(seed)
model <- train(
formula,
data = train,
method = method,
metric = metric,
trControl = trControl,
tuneLength = tuneLength,
tuneGrid = tuneGrid,
...
)
models[[method]] <- model
}
# result
result <- list(train = train,
test = test,
methods = methods,
models = models)
class(result) <- "quickmodel"
return(result)
}
library(ggplot2)
data(mpg)
View(mpg)
x <- quickmodel(cty ~ ., mpg)
View(x)
# main function
bestmodels <- function(models_list) {
best <- list()
# Finding the best model for quantitative models (lowest RMSE)
quant_models <- c("lm", "knn", "rf", "rpart", "gbm", "glmnet")
quant_models_list <- Filter(function(model) model$method %in% quant_models, models_list$models)
if (length(quant_models_list) > 0) {
# Extract RMSE values for each model in quant_models_list
rmse_values <- unlist(lapply(quant_models_list, function(model) model$results$RMSE))
if (length(rmse_values) > 0) {
# Find the index of the minimum RMSE value
best_model_index <- which.min(rmse_values)
# Check which model has the lowest RMSE value
print(paste("Best RMSE:", rmse_values[best_model_index]))
print(quant_models_list)
# Retrieve the best model based on the index
best_quant_model <- quant_models_list[[best_model_index]]
print(best_quant_model)
} else {
print("No RMSE values found.")
}
} else {
print("No models found for quantitative criteria.")
}
# Finding the best model for categorical models (highest Accuracy)
categ_models <- c("glm", "knn", "rf", "rpart", "gbm", "glmnet")
categ_models_list <- Filter(function(model) model$method %in% categ_models, models_list$models)
if (length(categ_models_list) > 0) {
# Extract Accuracy values for each model in categ_models_list
accuracy_values <- unlist(lapply(categ_models_list, function(model) model$results$Accuracy))
if (length(accuracy_values) > 0) {
# Find the index of the maximum Accuracy value
best_model_index <- which.max(accuracy_values)
# Retrieve the best model based on the index
best_categ_model <- categ_models_list[[best_model_index]]
best[["categorical"]] <- best_categ_model
} else {
best[["categorical"]] <- NULL
}
} else {
best[["categorical"]] <- NULL
}
return(best)
}
bestmodels(x)
data("PIMA")
data("PIMA", package = "regclass")
models_list <- quickmodel(Diabetes ~ ., PIMA)
#' @title Build multiple models
#' @description \code{quickmodel} will build multiple machine learning models with one function call.
#' @param formula An object of class "formula" (or one that can be coerced to that class): a symbolic description of the model to be fitted.
#' @param data Data frame from which variables specified in formula are preferentially to be taken.
#' @param metric A string that specifies what summary metric will be used to select the optimal model. By default, possible values are "RMSE" and "Rsquared" for regression and "Accuracy" for classification.
#' @param methods A character vector specifying which classification or regression model to use. By default, possible values are \code{c("lm", "knn", "rf", "rpart", "gbm", "glmnet")} for regression and \code{c("glm", "knn", "rf", "rpart", "gbm", "glmnet")} for classification.
#' @param trControl A list of values that define how this function acts. Default: trainControl()
#' @param tuneGrid A data frame with possible tuning values. The columns are named the same as the tuning parameters in each method preceded by a period (e.g. .decay, .lambda)., Default: NULL
#' @param tuneLength an integer denoting the number of levels for each tuning parameter that should be generated by createGrid. (NOTE: If given, this argument must be named.), Default: 3
#' @param partition The partition rate. Default: 0.8
#' @param seed The seed to do a random partition. Default: 1234
#' @param ... Optional parameters for \code{train} in \code{caret}
#' @return A list of class \code{quickmodel} with 4 components:
#' \describe{
#' \item{train}{The train dataset}
#' \item{test}{The test dataset}
#' \item{models}{A list of models}
#' \item{methods}{A character vector of machine learning models}
#' }
#' @details
#’ This function will take data and partition it into train and test datasets by the partition rate. It trains multiple machine learning models specified in methods.
#’ Note: If the user chooses to use any method that are not mentioned in default methods, they have to install and load corresponding packages first.
#' @examples
#’ data("PIMA", package="regclass")
#’ # classification models
#’ x=quickmodel(Diabetes~., data = PIMA)
#’ # regression models
#’ x=quickmodel(Age~., data = PIMA)
#' @import caret
#' @import randomForest
#' @import rpart
#' @import gbm
#' @import plyr
#' @import glmnet
#' @import Matrix
#' @rdname quickmodel
#' @export
quickmodel <- function(formula,
data, # all data
metric ,
methods ,
trControl = trainControl(),
tuneGrid = NULL,
tuneLength = 3,
partition = 0.8,
seed = 1234,
...
) {
# stop when the input dataset is too small
if (nrow(data)<100){
stop("Dataset too small.")
}
# quantitative
quant_models <- c("lm", "knn", "rf",
"rpart",
"gbm",
"glmnet")
# categorical
categ_models <- c("glm", "knn", "rf", "rpart", "gbm", "glmnet")
# if not installed then install
if (!require(caret)) {
install.packages("caret")
}
require("caret")
# extract y varname
y <- all.vars(formula)[1]
# change y var to factor if character
if (is.character(data[[y]])) {
data[[y]] <- factor(data[[y]])
}
# split data into train/test
set.seed(seed)
index <- createDataPartition(data[[y]], p = partition, list = FALSE)
train <- data[index, ]
test <- data[-index, ]
# set evaluation metric if not specified
if (missing(metric)) {
metric <- ifelse(is.factor(data[[y]]), "Accuracy", "RMSE")
}
# specify which models to train
if (missing(methods)){
if (is.factor(data[[y]])) {
methods <- categ_models
} else {
methods <- quant_models
}
}
# loading required packages
if ("gbm" %in% methods) {
require(gbm)
}
# model list
models <- list()
# train models
for (method in methods){
set.seed(seed)
model <- train(
formula,
data = train,
method = method,
metric = metric,
trControl = trControl,
tuneLength = tuneLength,
tuneGrid = tuneGrid,
...
)
models[[method]] <- model
}
# result
result <- list(train = train,
test = test,
methods = methods,
models = models)
class(result) <- "quickmodel"
return(result)
}
models_list <- quickmodel(Diabetes ~ ., PIMA)
best <- list()
# Finding the best model for quantitative models (lowest RMSE)
quant_models <- c("lm", "knn", "rf", "rpart", "gbm", "glmnet")
quant_models_list <- Filter(function(model) model$method %in% quant_models, models_list$models)
View(quant_models_list)
# Extract RMSE values for each model in quant_models_list
rmse_values <- unlist(lapply(quant_models_list, function(model) model$results$RMSE))
best <- list()
# Finding the best model for quantitative models (lowest RMSE)
quant_models <- c("lm", "knn", "rf", "rpart", "gbm", "glmnet")
quant_models_list <- Filter(function(model) model$method %in% quant_models, models_list$models)
# Extract RMSE values for each model in quant_models_list
rmse_values <- unlist(lapply(quant_models_list, function(model) model$results$RMSE))
