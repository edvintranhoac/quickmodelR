#' @title Build multiple models
#' @description \code{quickmodel} will build multiple machine learning models with one function call.
#' @param formula An object of class "formula" (or one that can be coerced to that class): a symbolic description of the model to be fitted.
#' @param data Data frame from which variables specified in formula are preferentially to be taken.
#' @param metric A string that specifies what summary metric will be used to select the optimal model. By default, possible values are "RMSE" and "Rsquared" for regression and "Accuracy" for classification.
#' @param methods A character vector specifying which classification or regression model to use. By default, possible values are \code{c("lm", "knn", "rf", "rpart", "gbm", "glmnet")} for regression and \code{c("glm", "knn", "rf", "rpart", "gbm", "glmnet")} for classification.
#' @param trControl A list of values that define how this function acts. Default: trainControl()
#' @param tuneGrid A data frame with possible tuning values. The columns are named the same as the tuning parameters in each method preceded by a period (e.g. .decay, .lambda)., Default: NULL
#' @param tuneLength an integer denoting the number of levels for each tuning parameter that should be generated by createGrid. (NOTE: If given, this argument must be named.), Default: 3
#' @param partition The partition rate. Default: 0.8
#' @param seed The seed to do a random partition. Default: 1234
#' @param ... Optional parameters for \code{train} in \code{caret}
#' @return A list of class \code{quickmodel} with 5 components:
#' \describe{
#' \item{train}{The train dataset}
#' \item{test}{The test dataset}
#' \item{models}{A list of models}
#' \item{methods}{A character vector of machine learning models}
#' \item{metric}{The selected metric. Default: "RMSE" for regression and "Accuracy" for classification.}
#' }
#' @details
#’ This function will take data and partition it into train and test datasets by the partition rate. It trains multiple machine learning models specified in methods.
#’ Note: If the user chooses to use any method that are not mentioned in default methods, they have to install and load corresponding packages first.
#' @examples
#’ # classification models
#' data("PIMA", package="regclass")
#’ x=quickmodel(Diabetes~., data = PIMA)
#’ # regression models
#' data(Boston, package="MASS")
#’ x=quickmodel(medv~., data = Boston)
#' @import caret
#' @import randomForest
#' @import rpart
#' @import gbm
#' @import plyr
#' @import glmnet
#' @import Matrix
#' @import regclass
#' @import MASS
#' @rdname quickmodel
#' @export

quickmodel <- function(formula,
                       data, # all data
                       metric ,
                       methods ,
                       trControl = trainControl(),
                       tuneGrid = NULL,
                       tuneLength = 3,
                       partition = 0.8,
                       seed=1234,
                       ...
                       ) {

  # stop when the input dataset is too small
  if (nrow(data)<100){
    stop("Dataset too small.")
  }

  # quantitative
  quant_models <- c("lm", "knn", "rf", "rpart", "gbm", "glmnet")

  # categorical
  categ_models <- c("glm", "knn", "rf", "rpart", "gbm", "glmnet")


  # if not installed then install
  if (!require(caret)) {
    install.packages("caret")
  }
  require("caret")

  # extract y varname
  y <- all.vars(formula)[1]

  # change y var to factor if character
  if (is.character(data[[y]])) {
    data[[y]] <- factor(data[[y]])
  }

  # split data into train/test
  set.seed(seed)
  index <- createDataPartition(data[[y]], p = partition, list = FALSE)
  train <- data[index, ]
  test <- data[-index, ]

  # set evaluation metric if not specified
  if (missing(metric)) {
    metric <- ifelse(is.factor(data[[y]]), "Accuracy", "RMSE")
  }

  # specify which models to train
  if (missing(methods)){
    if (is.factor(data[[y]])) {
      methods <- categ_models
    } else {
      methods <- quant_models
    }
  }

  # loading required packages
  if ("gbm" %in% methods) {
    require(gbm)
  }

  # model list
  models <- list()

  # train models
  for (method in methods){
    set.seed(seed)
    model <- train(
      formula,
      data = train,
      method = method,
      metric = metric,
      trControl = trControl,
      tuneLength = tuneLength,
      tuneGrid = tuneGrid,
      ...
    )
    models[[method]] <- model
  }

  # result
  result <- list(train = train,
                 test = test,
                 methods = methods,
                 models = models,
                 metric = metric
                 )
  class(result) <- "quickmodel"
  return(result)
}
